import os
import cv2
import joblib
import numpy as np
import pandas as pd
import mediapipe as mp
from flask import Flask, request, jsonify
from flask_cors import CORS

# ==========================================================
# 0. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
# ==========================================================
FRAME_INTERVAL = 3
UPLOAD_DIR = "./temp"
os.makedirs(UPLOAD_DIR, exist_ok=True)

mp_pose = mp.solutions.pose

# ML ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
print("ğŸ”¹ Loading ML artifacts...")
model = joblib.load("./result/best_model.pkl")
scaler = joblib.load("./result/best_scaler.pkl")
selected_features = joblib.load("./result/best_features.pkl")
print(f"âœ” Loaded. Features: {len(selected_features)}")


# ==========================================================
# 1. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì œê³µí•´ì£¼ì‹  ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼)
# ==========================================================
def fill_missing(arr):
    s = pd.Series(arr, dtype=float)
    s = s.interpolate(limit_direction="both").ffill().bfill()
    return s.to_numpy()


def center_point(p1, p2):
    return ((p1[0] + p2[0]) / 2.0, (p1[1] + p2[1]) / 2.0)


def velocity_series(pts, dt):
    v = [0.0]
    for i in range(1, len(pts)):
        dx = pts[i][0] - pts[i - 1][0]
        dy = pts[i][1] - pts[i - 1][1]
        v.append(np.sqrt(dx ** 2 + dy ** 2) / dt)
    return np.array(v)


def acc_series(v, dt):
    return np.gradient(v, dt)


def jerk_series(a, dt):
    return np.gradient(a, dt)


def body_size_from_landmarks(lm):
    def dist(i, j):
        return np.sqrt((lm[i].x - lm[j].x) ** 2 + (lm[i].y - lm[j].y) ** 2)

    pairs = [(11, 12), (23, 24), (11, 23), (12, 24)]
    return np.mean([dist(i, j) for i, j in pairs])


def limb_distance_series(pts):
    d = [0.0]
    for i in range(1, len(pts)):
        dx = pts[i][0] - pts[i - 1][0]
        dy = pts[i][1] - pts[i - 1][1]
        d.append(np.sqrt(dx ** 2 + dy ** 2))
    return np.array(d)


# ==========================================================
# 2. íŠ¹ì§• ì¶”ì¶œ (27ê°œ ë³€ìˆ˜ ë¡œì§ ë°˜ì˜)
# ==========================================================
def extract_features(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    fps = 30.0 if fps <= 0 else fps
    dt = 1.0 / fps

    hip_pts, lh_pts, rh_pts, lf_pts, rf_pts = [], [], [], [], []
    body_sizes = []
    frame_idx = 0

    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
        while True:
            ret, frame = cap.read()
            if not ret: break
            if frame_idx % FRAME_INTERVAL != 0:
                frame_idx += 1
                continue

            h, w = frame.shape[:2]
            res = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

            if res.pose_landmarks:
                lm = res.pose_landmarks.landmark
                body_sizes.append(body_size_from_landmarks(lm))
                L_HIP, R_HIP = (lm[23].x * w, lm[23].y * h), (lm[24].x * w, lm[24].y * h)
                hip_pts.append(center_point(L_HIP, R_HIP))
                lh_pts.append((lm[15].x * w, lm[15].y * h))
                rh_pts.append((lm[16].x * w, lm[16].y * h))
                lf_pts.append((lm[27].x * w, lm[27].y * h))
                rf_pts.append((lm[28].x * w, lm[28].y * h))
            else:
                for lst in [hip_pts, lh_pts, rh_pts, lf_pts, rf_pts]:
                    lst.append((np.nan, np.nan))
            frame_idx += 1
    cap.release()

    body_size = np.mean(body_sizes) if body_sizes else 1.0
    dt_eff = dt * FRAME_INTERVAL

    hip_x = fill_missing([p[0] for p in hip_pts])
    hip_y = fill_missing([p[1] for p in hip_pts])
    hip_xy = list(zip(hip_x, hip_y))

    # Fluency & Stability (Hip)
    v = velocity_series(hip_xy, dt_eff)
    a = acc_series(v, dt_eff)
    j = jerk_series(a, dt_eff)
    path = np.sum(v * dt_eff)
    total_time = len(hip_xy) * dt_eff

    feats = {
        "total_time": total_time,
        "fluency_hip_velocity_mean_norm": np.mean(v) / body_size,
        "fluency_hip_velocity_max_norm": np.max(v) / body_size,
        "fluency_hip_acc_mean_norm": np.mean(np.abs(a)) / body_size,
        "fluency_hip_acc_max_norm": np.max(np.abs(a)) / body_size,
        "fluency_hip_jerk_mean_norm": np.mean(np.abs(j)) / body_size,
        "fluency_hip_jerk_max_norm": np.max(np.abs(j)) / body_size,
        "fluency_hip_jerk_rms_norm": np.sqrt(np.mean(j ** 2)) / body_size,
        "fluency_hip_path_length_norm": path / body_size,
        "fluency_hip_path_per_sec_norm": path / total_time / body_size,
        "stability_hip_velocity_sd_norm": np.std(v) / body_size,
        "stability_hip_acc_sd_norm": np.std(a) / body_size,
        "stability_hip_jerk_sd_norm": np.std(j) / body_size,
    }

    # Limbs (Stability & Exploration)
    for name, pts in {"left_hand": lh_pts, "right_hand": rh_pts, "left_foot": lf_pts, "right_foot": rf_pts}.items():
        xs = fill_missing([p[0] for p in pts])
        ys = fill_missing([p[1] for p in pts])
        pts_clean = list(zip(xs, ys))
        lv = velocity_series(pts_clean, dt_eff)
        ld = limb_distance_series(pts_clean)
        feats[f"stability_{name}_velocity_sd_norm"] = np.std(lv) / body_size
        feats[f"exploration_{name}_velocity_mean_norm"] = np.mean(lv) / body_size
        feats[f"exploration_{name}_path_length_norm"] = np.sum(ld) / body_size

    return feats


# ==========================================================
# 3. í•œêµ­ì–´ í”¼ë“œë°± ìƒì„±
# ==========================================================
def generate_korean_feedback(feats):
    msg = []
    if feats.get("fluency_hip_jerk_mean_norm", 0) > 0.05:
        msg.append("ì›€ì§ì„ì´ ë‹¤ì†Œ ê¸‰í•©ë‹ˆë‹¤. ë¬´ê²Œ ì¤‘ì‹¬ì„ ë” ì²œì²œíˆ ì´ë™ì‹œì¼œ ë³´ì„¸ìš”.")
    else:
        msg.append("ì¤‘ì‹¬ ì´ë™ì´ ë§¤ìš° ë¶€ë“œëŸ½ê³  ì•ˆì •ì ì…ë‹ˆë‹¤.")

    if feats.get("stability_hip_velocity_sd_norm", 0) > 0.08:
        msg.append("ì¼ì •í•œ ì†ë„ë¥¼ ìœ ì§€í•˜ê¸°ë³´ë‹¤ ëŠê¸°ëŠ” ë™ì‘ì´ ë³´ì…ë‹ˆë‹¤. ë¦¬ë“¬ê°ì„ ë†’ì—¬ë³´ì„¸ìš”.")

    if feats.get("exploration_left_hand_path_length_norm", 0) + feats.get("exploration_right_hand_path_length_norm",
                                                                          0) > 1.5:
        msg.append("í™€ë“œë¥¼ ì¡ê¸° ì „ ì†ì˜ íƒìƒ‰ ë™ì‘ì´ ë§ìŠµë‹ˆë‹¤. ë‹¤ìŒ í™€ë“œë¥¼ ëª…í™•íˆ ì •í•˜ê³  ì›€ì§ì—¬ë³´ì„¸ìš”.")

    return msg if msg else ["ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ë“±ë°˜ì…ë‹ˆë‹¤."]


# ==========================================================
# 4. Flask ì„œë²„ ì„¤ì •
# ==========================================================
app = Flask(__name__)
CORS(app)


@app.route("/predict", methods=["POST"])
def predict():
    temp_path = None
    try:
        if "video" not in request.files:
            return jsonify({"error": "No video"}), 400

        video = request.files["video"]
        temp_path = os.path.join(UPLOAD_DIR, video.filename)
        video.save(temp_path)

        # 1. íŠ¹ì§• ì¶”ì¶œ
        feats = extract_features(temp_path)

        # 2. ML ì˜ˆì¸¡ ì „ìš© ë°ì´í„°ì…‹ êµ¬ì„± (Selected featuresë§Œ ì¶”ì¶œ)
        X = pd.DataFrame([feats]).reindex(columns=selected_features).fillna(0)
        if scaler:
            X[:] = scaler.transform(X)

        pred = int(model.predict(X)[0])
        prob = float(model.predict_proba(X)[0, 1])

        # 3. ì‘ë‹µ ë°ì´í„° êµ¬ì„± (í”ŒëŸ¬í„° ì•± í˜•ì‹)
        return jsonify({
            "prediction": {
                "label": "Advanced" if pred == 0 else "Intermediate",  # 0: Advanced, 1: Intermediate ê¸°ì¤€
                "probability": round(prob, 3)
            },
            "feedback_features": {k: round(float(v), 4) for k, v in feats.items()},
            "feedback_messages": generate_korean_feedback(feats)
        })

    except Exception as e:
        print(f"ğŸ”¥ Error: {e}")
        return jsonify({"error": str(e)}), 500
    finally:
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)