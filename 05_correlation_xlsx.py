import pandas as pd
import glob
from scipy.stats import shapiro, pearsonr, spearmanr
import networkx as nx
import os

os.makedirs('./result', exist_ok=True)

def analyze_and_filter_with_grouping(df):
    metrics = [col for col in df.columns if col not in ['id', 'label']]
    results = []

    # 1ï¸âƒ£ ì •ê·œì„±ì— ë”°ë¥¸ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
    for i in range(len(metrics)):
        for j in range(i+1, len(metrics)):
            var1, var2 = metrics[i], metrics[j]
            data = df[[var1, var2]].dropna()
            if len(data) < 3:
                continue

            x, y = data[var1], data[var2]
            p_norm_x = shapiro(x).pvalue
            p_norm_y = shapiro(y).pvalue

            if p_norm_x > 0.05 and p_norm_y > 0.05:
                corr, pval = pearsonr(x, y)
                method = 'Pearson'
            else:
                corr, pval = spearmanr(x, y)
                method = 'Spearman'

            results.append({
                'ë³€ìˆ˜1': var1,
                'ë³€ìˆ˜2': var2,
                'ìƒê´€ê³„ìˆ˜': round(corr, 4),
                'ì‚¬ìš©ëœë°©ë²•': method,
                'var1_ì •ê·œì„±_p': round(p_norm_x, 4),
                'var2_ì •ê·œì„±_p': round(p_norm_y, 4)
            })

    res_df = pd.DataFrame(results)

    # 2ï¸âƒ£ ìƒê´€ê³„ìˆ˜ê°€ 0.9 ì´ìƒì¸ ë³€ìˆ˜ìŒ ì¶”ì¶œ
    high_corr_df = res_df[res_df['ìƒê´€ê³„ìˆ˜'].abs() >= 0.9].copy()

    # 3ï¸âƒ£ ë„¤íŠ¸ì›Œí¬ë¡œ ê·¸ë£¹í™” í›„ ì œê±° ë³€ìˆ˜ ê²°ì •
    G = nx.Graph()
    G.add_edges_from(zip(high_corr_df['ë³€ìˆ˜1'], high_corr_df['ë³€ìˆ˜2']))

    to_keep = []
    to_drop = []

    for group in nx.connected_components(G):
        group = list(group)
        to_keep.append(group[0])         # ê·¸ë£¹ì—ì„œ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³ 
        to_drop.extend(group[1:])        # ë‚˜ë¨¸ì§€ëŠ” ì œê±°

    # ê·¸ë£¹ì— ì†í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ + ê·¸ë£¹ì—ì„œ ë‚¨ê¸´ ë³€ìˆ˜
    all_grouped = set(high_corr_df['ë³€ìˆ˜1']).union(high_corr_df['ë³€ìˆ˜2'])
    remaining_vars = [v for v in metrics if (v in to_keep) or (v not in all_grouped)]

    return res_df, high_corr_df, to_keep, to_drop, remaining_vars


# ğŸ”· ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
dfs = []
for file in glob.glob('./features_xlsx/*.xlsx'):
    df_tmp = pd.read_excel(file, sheet_name=0)
    dfs.append(df_tmp)

if not dfs:
    raise FileNotFoundError("âŒ './features_xlsx/' í´ë”ì— .xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

df = pd.concat(dfs, ignore_index=True)

# ğŸ”· ë¶„ì„
res_df, high_corr_df, to_keep, to_drop, remaining_vars = analyze_and_filter_with_grouping(df)

# ğŸ”· ê²°ê³¼ ì¶œë ¥
print("\nğŸ“‹ ì •ê·œì„±ì— ë”°ë¼ ê³„ì‚°ëœ ìƒê´€ê³„ìˆ˜ ê²°ê³¼ (ì•ë¶€ë¶„):")
print(res_df.head())

print("\nğŸ“Œ ìƒê´€ê³„ìˆ˜ >= 0.9ì¸ ë³€ìˆ˜ìŒ:")
print(high_corr_df)

print("\nâœ… ê° ê·¸ë£¹ì—ì„œ ë‚¨ê¸´ ë³€ìˆ˜:")
print(to_keep)

print("\nğŸ§¹ ì œê±°í•œ ë³€ìˆ˜:")
print(to_drop)

print("\nğŸ¯ ìµœì¢… ë‚¨ì€ ë³€ìˆ˜:")
print(remaining_vars)

# ğŸ”· ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥
with pd.ExcelWriter('./result/correlation_analysis_with_groups.xlsx') as writer:
    res_df.to_excel(writer, sheet_name='ëª¨ë“ _ìŒ_ê²°ê³¼', index=False)
    high_corr_df.to_excel(writer, sheet_name='0.9ì´ìƒ_ìŒ', index=False)
    pd.DataFrame({'ê·¸ë£¹ë³„_ë‚¨ê¸´ë³€ìˆ˜': to_keep}).to_excel(writer, sheet_name='ê·¸ë£¹ë³„_ë‚¨ê¸´ë³€ìˆ˜', index=False)
    pd.DataFrame({'ì œê±°í•œë³€ìˆ˜': to_drop}).to_excel(writer, sheet_name='ì œê±°í•œë³€ìˆ˜', index=False)
    pd.DataFrame({'ìµœì¢…ë‚¨ì€ë³€ìˆ˜': remaining_vars}).to_excel(writer, sheet_name='ìµœì¢…ë‚¨ì€ë³€ìˆ˜', index=False)

print("\nğŸ“ ê²°ê³¼ê°€ './result/correlation_analysis_with_groups.xlsx' ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
