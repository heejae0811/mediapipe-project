"""
ğŸ“š ë‹¨ê³„ë³„ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸
1ë‹¨ê³„: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
2ë‹¨ê³„: Train/Test ë¶„ë¦¬ (8:2)
3ë‹¨ê³„: Data Scaling (í‘œì¤€í™”)
4ë‹¨ê³„: Feature Selection (RF ê¸°ë°˜ Top-K)
5ë‹¨ê³„: 8ê°œ ML ëª¨ë¸ í•™ìŠµ (ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°)
6ë‹¨ê³„: ML Evaluation (ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ê³„ì‚°)
7ë‹¨ê³„: ì—‘ì…€ ì €ì¥ ë° ì‹œê°í™”
8ë‹¨ê³„: XAI (LIME + SHAP)
"""

import os
import glob
import warnings
import random
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from kneed import KneeLocator
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, balanced_accuracy_score, roc_curve, auc)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lime.lime_tabular import LimeTabularExplainer
import joblib


# =====================================================
# ì „ì—­ ì„¤ì •
# =====================================================
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)
random.seed(RANDOM_STATE)

RESULT_DIR = "./result"
os.makedirs(RESULT_DIR, exist_ok=True)

warnings.filterwarnings("ignore")


# =====================================================
# 1ë‹¨ê³„: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# =====================================================
def data_load():
    print("\n[1ë‹¨ê³„] Data Load")

    files = glob.glob("./features_xlsx/*.xlsx")
    print(f"ì°¾ì€ íŒŒì¼ ìˆ˜: {len(files)}")

    if len(files) == 0:
        raise FileNotFoundError("âŒ í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df_list = [pd.read_excel(f) for f in files]
    df = pd.concat(df_list, ignore_index=True)

    if "label" not in df.columns:
        raise KeyError("âŒ label ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    y = df["label"].astype(int).values
    class_names = ["Intermediate", "Advanced"]
    label_counts = np.bincount(y)

    # ìˆ«ìí˜• feature ìë™ ì„ íƒ
    feature_cols = df.select_dtypes(include=["float64", "int64"]).columns
    feature_cols = feature_cols.drop("label", errors="ignore")

    X = df[feature_cols]

    # ê²°ì¸¡ì¹˜ í™•ì¸
    total_missing = X.isnull().sum().sum()
    print(f"ê²°ì¸¡ì¹˜ ê°œìˆ˜: {total_missing}")

    if total_missing > 0:
        print("âš ï¸ ê²½ê³ : ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. \n")

    print(f"Feature ê°œìˆ˜: {len(feature_cols)}")
    print(f"ì‚¬ìš© í´ë˜ìŠ¤: {class_names}")
    print(f"í´ë˜ìŠ¤ ë¶„í¬: 0 - {label_counts[0]}ê°œ, 1 - {label_counts[1]}ê°œ")

    return X, y, list(feature_cols), class_names


# =====================================================
# 2ë‹¨ê³„: Train/Test ë¶„ë¦¬
# =====================================================
def data_split(X, y, test_size=0.2):
    print("\n[2ë‹¨ê³„] Train/Test Split")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        stratify=y,
        random_state=RANDOM_STATE
    )

    print(f"Train ìƒ˜í”Œ ìˆ˜: {len(X_train)}")
    print(f"Test ìƒ˜í”Œ ìˆ˜: {len(X_test)}")
    print(f"Train í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_train)}")
    print(f"Test  í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(y_test)}")

    return X_train, X_test, y_train, y_test


# =====================================================
# 3ë‹¨ê³„: Feature Scaling
# =====================================================
def feature_scaling(X_train, X_test, model_name):
    print("\n[3ë‹¨ê³„] Feature Scaling")

    # ìŠ¤ì¼€ì¼ë§ì´ í•„ìš”í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
    scaling_required = ["Logistic Regression", "KNN", "SVM"]

    # ìŠ¤ì¼€ì¼ë§ í•„ìš” ì—†ëŠ” ëª¨ë¸ ë°˜í™˜
    if model_name not in scaling_required:
        print(f"âš ï¸ ìŠ¤ì¼€ì¼ë§ ìƒëµ: {model_name}")
        return X_train, X_test, None

    print(f"âœ” ìŠ¤ì¼€ì¼ë§ ì ìš©: {model_name}")

    # ê²°ì¸¡ì¹˜ëŠ” Train ê¸°ì¤€ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    train_median = X_train.median()
    X_train_filled = X_train.fillna(train_median)
    X_test_filled = X_test.fillna(train_median)

    scaler = StandardScaler()
    scaler.fit(X_train_filled)

    X_train_scaled = pd.DataFrame(
        scaler.transform(X_train_filled),
        columns=X_train.columns,
        index=X_train.index
    )

    X_test_scaled = pd.DataFrame(
        scaler.transform(X_test_filled),
        columns=X_test.columns,
        index=X_test.index
    )

    print("âœ” Scaling ì™„ë£Œ (í‰ê·  0, í‘œì¤€í¸ì°¨ 1 ê¸°ì¤€)")

    return X_train_scaled, X_test_scaled, scaler


# =====================================================
# 4ë‹¨ê³„: Feature Selection
# =====================================================
def feature_selection_rf(X_train, y_train, plot_path=None):
    print("\n[4ë‹¨ê³„] Feature Selection")

    # 1) Random Forest í•™ìŠµ
    rf = RandomForestClassifier(
        n_estimators=600,
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)

    # 2) Feature Importance ì •ë ¬
    importances = rf.feature_importances_
    idx_sorted = np.argsort(importances)[::-1]

    sorted_imp = importances[idx_sorted]
    sorted_feat = X_train.columns[idx_sorted]

    # 3) xì¶• = feature index, yì¶• = importance
    x = np.arange(1, len(sorted_imp) + 1)
    y = sorted_imp

    # 4) Kneedle ì•Œê³ ë¦¬ì¦˜
    kn = KneeLocator(
        x, y,
        curve='convex',
        direction='decreasing'
    )

    elbow_k = kn.knee

    # kneeë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ëŒ€ë¹„
    if elbow_k is None:
        print("âš ï¸ Kneedleì´ kneeë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ K=5 ì‚¬ìš©í•©ë‹ˆë‹¤.")
        elbow_k = 5

    elbow_k = int(elbow_k)
    elbow_k = max(3, elbow_k)

    selected_features = list(sorted_feat[:elbow_k])

    if plot_path:
        plt.figure(figsize=(8, 5))
        plt.plot(x, y, marker="o")
        if kn.knee is not None:
            plt.axvline(elbow_k, color="red", linestyle="--", label=f"Knee = {elbow_k}")
        plt.title("Random Forest Feature Importance (Kneedle Algorithm)")
        plt.xlabel("Feature Rank")
        plt.ylabel("Importance")
        plt.legend()
        plt.tight_layout()
        plt.savefig(plot_path, dpi=300)
        plt.close()

    return selected_features, sorted_feat, sorted_imp, elbow_k


# =====================================================
# 5ë‹¨ê³„: 8ê°œ ML ëª¨ë¸ ì •ì˜ (ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°)
# =====================================================
def get_models():
    print("\n[5ë‹¨ê³„] ML ëª¨ë¸ ìƒì„±")

    models = {
        "Logistic Regression": LogisticRegression(
            max_iter=1000,
            random_state=RANDOM_STATE
        ),
        "KNN": KNeighborsClassifier(),
        "SVM": SVC(
            probability=True,
            random_state=RANDOM_STATE
        ),
        "Decision Tree": DecisionTreeClassifier(
            random_state=RANDOM_STATE
        ),
        "Random Forest": RandomForestClassifier(
            random_state=RANDOM_STATE,
            n_estimators=200,
            n_jobs=-1
        ),
        "LightGBM": LGBMClassifier(
            random_state=RANDOM_STATE,
            n_jobs=-1
        ),
        "XGBoost": XGBClassifier(
            random_state=RANDOM_STATE,
            eval_metric="logloss",
            n_jobs=-1,
            use_label_encoder=False
        ),
        "CatBoost": CatBoostClassifier(
            random_state=RANDOM_STATE,
            verbose=False
        ),
    }

    print(f"ëª¨ë¸ ê°œìˆ˜: {len(models)}ê°œ")
    return models


# =====================================================
# 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ + í‰ê°€
# =====================================================
def evaluate_models(models, X_train, y_train, X_test, y_test):
    print("\n[6ë‹¨ê³„] ëª¨ë¸ í•™ìŠµ ë° í‰ê°€")

    results_list = []
    y_proba_dict = {}
    model_objects = {}

    for name, model in models.items():
        print(f"\nâš¡ Training: {name}")

        # 1) ëª¨ë¸ í•™ìŠµ
        model.fit(X_train, y_train)

        # 2) ì˜ˆì¸¡ (ë¼ë²¨, í™•ë¥ )
        y_pred = model.predict(X_test)
        # ì´ì§„ë¶„ë¥˜ë¼ê³  ê°€ì •í•˜ê³ , ì–‘ì„± í´ë˜ìŠ¤(1)ì˜ í™•ë¥ ë§Œ ì‚¬ìš©
        y_proba = model.predict_proba(X_test)[:, 1]

        # 3) ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        cm = confusion_matrix(y_test, y_pred)
        tn, fp, fn, tp = cm.ravel()

        accuracy = (y_pred == y_test).mean()
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)  # sensitivity
        f1 = f1_score(y_test, y_pred, zero_division=0)
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
        bal_acc = balanced_accuracy_score(y_test, y_pred)
        mcc = matthews_corrcoef(y_test, y_pred)
        auc_score = roc_auc_score(y_test, y_proba)

        result = {
            "Model": name,
            "Accuracy": accuracy,
            "Precision": precision,
            "Recall": recall,
            "F1": f1,
            "Specificity": specificity,
            "Sensitivity": sensitivity,
            "Balanced_Accuracy": bal_acc,
            "MCC": mcc,
            "AUC": auc_score
        }
        results_list.append(result)

        y_proba_dict[name] = y_proba
        model_objects[name] = model

        print(f"   - Accuracy: {accuracy:.3f}, F1: {f1:.3f}, MCC: {mcc:.3f}, AUC: {auc_score:.3f}")

    # MCC ê¸°ì¤€ìœ¼ë¡œ Best Model ì„ ì •
    df_results = pd.DataFrame(results_list)
    best_idx = df_results["MCC"].idxmax()
    best_model_name = df_results.loc[best_idx, "Model"]
    best_model = model_objects[best_model_name]

    print(f"\nâœ… Best Model (MCC ê¸°ì¤€): {best_model_name}")

    return results_list, y_proba_dict, best_model_name, best_model


# =====================================================
# 7ë‹¨ê³„: ì—‘ì…€ ì €ì¥ ë° ì‹œê°í™”
# =====================================================
def save_results_and_plots(results_list, y_test, y_proba_dict, best_model_name, best_model, X_test_fs, selected_features, class_names):
    print("\n[7ë‹¨ê³„] ì—‘ì…€ ì €ì¥ ë° ì‹œê°í™”")

    df_results = pd.DataFrame(results_list)
    df_results_sorted = df_results.sort_values("MCC", ascending=False)

    # 1) ì—‘ì…€ ì €ì¥
    excel_path = os.path.join(RESULT_DIR, "final_results.xlsx")
    df_results_sorted.to_excel(excel_path, index=False)
    print(f"ì„±ëŠ¥ ì§€í‘œ ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {excel_path}")

    # 2) Confusion Matrix (Best Model)
    y_pred_best = best_model.predict(X_test_fs)
    cm = confusion_matrix(y_test, y_pred_best)

    plt.figure(figsize=(7, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.title(f"Confusion Matrix - {best_model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    cm_path = os.path.join(RESULT_DIR, "confusion_matrix_best.png")
    plt.savefig(cm_path, dpi=300)
    plt.close()
    print(f"Confusion Matrix ì €ì¥: {cm_path}")

    # 3) ROC Curve (ëª¨ë“  ëª¨ë¸ ë¹„êµ)
    plt.figure(figsize=(7, 6))
    for name, y_proba in y_proba_dict.items():
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, lw=2, label=f"{name} (AUC={roc_auc:.3f})")

    plt.plot([0, 1], [0, 1], "k--", label="Random")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve Comparison (All Models)")
    plt.legend(loc="lower right", fontsize=8)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    roc_all_path = os.path.join(RESULT_DIR, "roc_all_models.png")
    plt.savefig(roc_all_path, dpi=300)
    plt.close()
    print(f"ROC Curve ì €ì¥: {roc_all_path}")

    # 4) Feature Importance (ì§€ì› ì•ˆë˜ë©´ Permutation Importance ì‚¬ìš©)
    if hasattr(best_model, "feature_importances_"):
        # Tree ëª¨ë¸ Feature Importance
        importances = best_model.feature_importances_
        df_fi = pd.DataFrame({
            "Feature": selected_features,
            "Importance": importances
        })
    else:
        # Permutation Importanceë¡œ ëŒ€ì²´
        from sklearn.inspection import permutation_importance

        perm = permutation_importance(
            best_model,
            X_test_fs,
            y_test,
            scoring="matthews_corrcoef",
            n_repeats=10,
            random_state=42
        )
        df_fi = pd.DataFrame({
            "Feature": selected_features,
            "Importance": perm.importances_mean
        })


# =====================================================
# 8ë‹¨ê³„: XAI (LIME + SHAP)
# =====================================================
def run_xai(best_model, X_train_fs, X_test_fs, selected_features, class_names):
    """
    Best Modelì„ ëŒ€ìƒìœ¼ë¡œ LIME, SHAP ì‹¤í–‰.
    - LIME: ê°œë³„ ìƒ˜í”Œì— ëŒ€í•œ êµ­ì†Œ(local) ì„¤ëª…
    - SHAP: ì „ì²´ì ì¸(global) feature ì¤‘ìš”ë„ ì„¤ëª… (Tree ê¸°ë°˜ ëª¨ë¸ì—ì„œ)
    """
    print("\n[8ë‹¨ê³„] XAI (LIME + SHAP) ì‹¤í–‰")

    # ---------- LIME ----------
    print("LIME ì‹¤í–‰ ì¤‘...")
    try:
        explainer = LimeTabularExplainer(
            training_data=np.array(X_train_fs),
            feature_names=selected_features,
            class_names=class_names,
            mode="classification"
        )

        # ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì„ íƒ
        sample = X_test_fs.iloc[0].values

        def predict_fn(x):
            return best_model.predict_proba(x)

        exp = explainer.explain_instance(sample, predict_fn)
        lime_path = os.path.join(RESULT_DIR, "lime_explanation_best.html")
        exp.save_to_file(lime_path)
        print(f"LIME ê²°ê³¼ ì €ì¥: {lime_path}")
    except Exception as e:
        print(f"âŒ LIME ì‹¤í–‰ ì‹¤íŒ¨: {e}")


# =====================================================
# 9ë‹¨ê³„: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ì €ì¥
# =====================================================
def save_final_artifacts(best_model, scaler, selected_features):
    print("\n[ì €ì¥ ë‹¨ê³„] ëª¨ë¸ / ìŠ¤ì¼€ì¼ëŸ¬ / í”¼ì²˜ ì €ì¥")

    model_path = "./result/best_model.pkl"
    scaler_path = "./result/scaler.pkl"
    features_path = "./result/selected_features.pkl"

    joblib.dump(best_model, model_path)
    joblib.dump(scaler, scaler_path)
    joblib.dump(selected_features, features_path)

    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    print(f"âœ… ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: {scaler_path}")
    print(f"âœ… í”¼ì²˜ ì €ì¥ ì™„ë£Œ: {features_path}")


# =====================================================
# MAIN: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
# =====================================================
def main():
    print("\n============================================")
    print("ğŸš€ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("============================================")

    # 1ë‹¨ê³„: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    X, y, feature_names, class_names = data_load()

    # 2ë‹¨ê³„: Train/Test ë¶„ë¦¬
    X_train, X_test, y_train, y_test = data_split(X, y, test_size=0.2)

    # 3ë‹¨ê³„: Feature Scaling
    X_train_scaled, X_test_scaled, scaler = feature_scaling(X_train, X_test, model_name)

    # 4ë‹¨ê³„: Feature Selection
    selected_features, sorted_feat, sorted_imp, K = feature_selection_rf(
        X_train_scaled, y_train, "./result/rf_importance_curve.png"
    )
    print(f"Selected Feature({K}ê°œ): {selected_features}")

    X_train_fs = X_train_scaled[selected_features]
    X_test_fs = X_test_scaled[selected_features]

    # 5ë‹¨ê³„: ëª¨ë¸ ìƒì„±
    models = get_models()

    # 6ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ + í‰ê°€
    results_list, y_proba_dict, best_model_name, best_model = evaluate_models(
        models, X_train_fs, y_train, X_test_fs, y_test
    )

    # 7ë‹¨ê³„: ì‹œê°í™” ë° ì—‘ì…€ ì €ì¥
    save_results_and_plots(
        results_list, y_test, y_proba_dict,
        best_model_name, best_model,
        X_test_fs, selected_features, class_names
    )

    # 8ë‹¨ê³„: XAI (LIME)
    run_xai(best_model, X_train_fs, X_test_fs, selected_features, class_names)

    # 9ë‹¨ê³„: ì„œë²„ ì €ì¥
    save_final_artifacts(best_model, scaler, selected_features)

    print("\nğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ! result í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


# =====================================================
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# =====================================================
if __name__ == "__main__":
    main()
